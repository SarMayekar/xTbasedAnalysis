{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy statsbombpy matplotlib seaborn plotly networkx notebook\n",
    "\n",
    "import pandas as pd\n",
    "from statsbombpy import sb\n",
    "\n",
    "# --------------------------------------------\n",
    "# Configuration\n",
    "# --------------------------------------------\n",
    "OUTPUT_DIR = r\"E:\\MSc Big Data Analytics in Football\\WSL project\\Statsbombpy data\"\n",
    "MATCH_FILE = \"wsl_matches_all.csv\"\n",
    "EVENT_FILE = \"wsl_events_all.csv\"\n",
    "\n",
    "# Define WSL seasons to fetch\n",
    "WSL_SEASONS = [\n",
    "    {\"competition_id\": 37, \"season_id\": 4, \"season_name\": \"2018/2019\"},\n",
    "    {\"competition_id\": 37, \"season_id\": 42, \"season_name\": \"2019/2020\"},\n",
    "    {\"competition_id\": 37, \"season_id\": 90, \"season_name\": \"2020/2021\"},\n",
    "    {\"competition_id\": 1238, \"season_id\": 108, \"season_name\": \"2021/2022\"},\n",
    "]\n",
    "\n",
    "# --------------------------------------------\n",
    "# Functions\n",
    "# --------------------------------------------\n",
    "def find_wsl_competitions():\n",
    "    \"\"\"Find all WSL competitions from StatsBomb data.\"\"\"\n",
    "    comps = sb.competitions()\n",
    "    wsl_comps = comps[comps['competition_name'].str.contains(\"Super League\", case=False)]\n",
    "    print(\"WSL Competitions Found:\")\n",
    "    print(wsl_comps[['competition_id', 'season_id', 'season_name']])\n",
    "    return wsl_comps\n",
    "\n",
    "def prepare_events(match_id):\n",
    "    \"\"\"Prepare event data for a given match ID.\"\"\"\n",
    "    df = sb.events(match_id=match_id)\n",
    "    cols = [\n",
    "        'id', 'type', 'team', 'player', 'minute', 'second',\n",
    "        'location', 'pass_end_location', 'shot_statsbomb_xg',\n",
    "        'shot_outcome', 'carry_end_location', 'possession', 'possession_team'\n",
    "    ]\n",
    "    df_clean = df[cols].copy()\n",
    "    df_clean['match_id'] = match_id\n",
    "    return df_clean\n",
    "\n",
    "def collect_season_data():\n",
    "    \"\"\"Fetch match and event data for all defined WSL seasons.\"\"\"\n",
    "    all_matches = []\n",
    "    all_events = []\n",
    "\n",
    "    for season in WSL_SEASONS:\n",
    "        cid, sid, sname = season[\"competition_id\"], season[\"season_id\"], season[\"season_name\"]\n",
    "        print(f\"\\nFetching WSL {sname} (competition_id={cid}, season_id={sid}) ...\")\n",
    "        matches = sb.matches(competition_id=cid, season_id=sid)\n",
    "        print(f\" ‚Üí {matches.shape[0]} matches loaded\")\n",
    "        matches['season_name'] = sname\n",
    "        all_matches.append(matches)\n",
    "\n",
    "        for mid in matches.match_id:\n",
    "            ev = prepare_events(mid)\n",
    "            ev['season_name'] = sname\n",
    "            all_events.append(ev)\n",
    "\n",
    "    return all_matches, all_events\n",
    "\n",
    "# --------------------------------------------\n",
    "# Main Execution\n",
    "# --------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Find WSL competitions\n",
    "    find_wsl_competitions()\n",
    "\n",
    "    # Step 2: Collect match and event data\n",
    "    all_matches, all_events = collect_season_data()\n",
    "\n",
    "    # Step 3: Concatenate data\n",
    "    matches_df = pd.concat(all_matches, ignore_index=True)\n",
    "    events_df = pd.concat(all_events, ignore_index=True)\n",
    "    print(f\"\\n‚úÖ Total Matches Collected: {matches_df.shape[0]}\")\n",
    "    print(f\"‚úÖ Total Events Collected: {events_df.shape[0]}\")\n",
    "\n",
    "    # Step 4: Save to CSV\n",
    "    matches_df.to_csv(os.path.join(OUTPUT_DIR, MATCH_FILE), index=False)\n",
    "    events_df.to_csv(os.path.join(OUTPUT_DIR, EVENT_FILE), index=False)\n",
    "    print(f\"\\nüíæ Saved: '{MATCH_FILE}' and '{EVENT_FILE}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56910465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --------------------------------------------\n",
    "# Configuration\n",
    "# --------------------------------------------\n",
    "BASE_DIR = r\"E:\\MSc Big Data Analytics in Football\\WSL project\\FbRef\"\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"processed\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define seasons\n",
    "SEASONS = {\n",
    "    \"18-19\": \"2018/2019\",\n",
    "    \"19-20\": \"2019/2020\",\n",
    "    \"20-21\": \"2020/2021\",\n",
    "    \"21-22\": \"2021/2022\"\n",
    "}\n",
    "\n",
    "# File categories\n",
    "TEAM_FILES = [\"Team Stats\", \"Team GK\", \"Team Shooting\", \"Team Passing\", \"Team Possession\", \"Team Def Actions\"]\n",
    "PLAYER_FILES = [\"Player Stats\", \"Player GK\", \"Player Shooting\", \"Player Passing\", \"Player Possession\", \"Player Def Actions\"]\n",
    "\n",
    "# --------------------------------------------\n",
    "# Functions\n",
    "# --------------------------------------------\n",
    "def load_fbref_data(season_folder, season_label, file_list, level=\"team\"):\n",
    "    \"\"\"Load and tag FbRef CSVs for one season.\"\"\"\n",
    "    dfs = []\n",
    "    for fname in file_list:\n",
    "        path = os.path.join(BASE_DIR, season_folder, f\"{fname}.xlsx\")\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_excel(path)\n",
    "            df[\"season\"] = season_label\n",
    "            df[\"stat_category\"] = fname\n",
    "            df[\"level\"] = level\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Missing file: {path}\")\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "# --------------------------------------------\n",
    "# Main Execution\n",
    "# --------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Collect team and player data\n",
    "    team_dfs = []\n",
    "    player_dfs = []\n",
    "    for folder, label in SEASONS.items():\n",
    "        print(f\"üìÇ Processing {folder} ({label}) ...\")\n",
    "        team_dfs.append(load_fbref_data(folder, label, TEAM_FILES, level=\"team\"))\n",
    "        player_dfs.append(load_fbref_data(folder, label, PLAYER_FILES, level=\"player\"))\n",
    "\n",
    "    # Step 2: Concatenate data\n",
    "    team_all = pd.concat(team_dfs, ignore_index=True)\n",
    "    player_all = pd.concat(player_dfs, ignore_index=True)\n",
    "\n",
    "    # Step 3: Save to CSV\n",
    "    team_all.to_csv(os.path.join(OUTPUT_DIR, \"fbref_team_all.csv\"), index=False)\n",
    "    player_all.to_csv(os.path.join(OUTPUT_DIR, \"fbref_player_all.csv\"), index=False)\n",
    "    print(\"‚úÖ FbRef consolidation complete!\")\n",
    "    print(f\"Team dataset: {team_all.shape}\")\n",
    "    print(f\"Player dataset: {player_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ab5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --------------------------------------------\n",
    "# Configuration\n",
    "# --------------------------------------------\n",
    "BASE_DIR = r\"E:\\MSc Big Data Analytics in Football\\WSL project\\Statsbombpy data\"\n",
    "MATCH_FILE = os.path.join(BASE_DIR, \"wsl_matches_all.csv\")\n",
    "EVENT_FILE = os.path.join(BASE_DIR, \"wsl_events_all.csv\")\n",
    "OUTPUT_FILE = os.path.join(BASE_DIR, \"wsl_events_with_gamestate.csv\")\n",
    "\n",
    "# --------------------------------------------\n",
    "# Functions\n",
    "# --------------------------------------------\n",
    "def load_data():\n",
    "    \"\"\"Load match and event data.\"\"\"\n",
    "    matches_df = pd.read_csv(MATCH_FILE)\n",
    "    events_df = pd.read_csv(EVENT_FILE)\n",
    "    print(\"Matches:\", matches_df.shape)\n",
    "    print(\"Events:\", events_df.shape)\n",
    "    return matches_df, events_df\n",
    "\n",
    "def build_match_info(matches_df):\n",
    "    \"\"\"Create dictionary of match_id to home/away teams.\"\"\"\n",
    "    match_info = {}\n",
    "    for _, row in matches_df.iterrows():\n",
    "        match_info[row[\"match_id\"]] = {\n",
    "            \"home\": row[\"home_team\"],\n",
    "            \"away\": row[\"away_team\"],\n",
    "        }\n",
    "    return match_info\n",
    "\n",
    "def add_game_state(events_df, match_info):\n",
    "    \"\"\"Add game state to events based on current score.\"\"\"\n",
    "    events_df = events_df.sort_values(by=[\"match_id\", \"minute\", \"second\"]).reset_index(drop=True)\n",
    "    game_states = []\n",
    "    score_home, score_away = 0, 0\n",
    "    current_match = None\n",
    "\n",
    "    for _, ev in events_df.iterrows():\n",
    "        match_id = ev[\"match_id\"]\n",
    "        # Reset scores for new match\n",
    "        if match_id != current_match:\n",
    "            current_match = match_id\n",
    "            score_home, score_away = 0, 0\n",
    "        home = match_info[match_id][\"home\"]\n",
    "        away = match_info[match_id][\"away\"]\n",
    "        team = ev[\"team\"]\n",
    "        event_type = ev[\"type\"]\n",
    "\n",
    "        # Update score if goal\n",
    "        if event_type == \"Shot\" and ev.get(\"shot_outcome\") == \"Goal\":\n",
    "            if team == home:\n",
    "                score_home += 1\n",
    "            elif team == away:\n",
    "                score_away += 1\n",
    "\n",
    "        # Assign game state\n",
    "        if team == home:\n",
    "            if score_home > score_away:\n",
    "                game_state = \"winning\"\n",
    "            elif score_home < score_away:\n",
    "                game_state = \"losing\"\n",
    "            else:\n",
    "                game_state = \"drawing\"\n",
    "        elif team == away:\n",
    "            if score_away > score_home:\n",
    "                game_state = \"winning\"\n",
    "            elif score_away < score_home:\n",
    "                game_state = \"losing\"\n",
    "            else:\n",
    "                game_state = \"drawing\"\n",
    "        else:\n",
    "            game_state = None\n",
    "        game_states.append(game_state)\n",
    "\n",
    "    events_df[\"game_state\"] = game_states\n",
    "    return events_df\n",
    "\n",
    "# --------------------------------------------\n",
    "# Main Execution\n",
    "# --------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load data\n",
    "    matches_df, events_df = load_data()\n",
    "\n",
    "    # Step 2: Build match info\n",
    "    match_info = build_match_info(matches_df)\n",
    "\n",
    "    # Step 3: Add game state\n",
    "    events_df = add_game_state(events_df, match_info)\n",
    "\n",
    "    # Step 4: Save output\n",
    "    events_df.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "    print(\"‚úÖ Game state labeling complete!\")\n",
    "    print(\"Saved file:\", OUTPUT_FILE)\n",
    "    print(\"Shape:\", events_df.shape)\n",
    "    print(events_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (football)",
   "language": "python",
   "name": "football"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
